{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '25 May.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-9fe8a1556442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'25 May.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '25 May.csv'"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('25 May.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning plan\n",
    "* While collecting the data, some \"location\" codes were updated after few days.\n",
    "     * Overwrite all previous instances of the location to the new location code.\n",
    "* For the initial days, \"points_flowering\" was not being used. Consider this attribute from 19 march onwards.\n",
    "     * For days after 19 Mar, replace nan with 0.\n",
    "     * Transitions \"->\" can be summarised in a different table to check inference for many vines initiating new point flowering together (these points were discovered but in dormant state).\n",
    "     * In main table, only the current number of active flowering points (transitioned value of '->'), is relevant.\n",
    "* \"Total_points\" transitions \"->\" can be summarised in a different table. \n",
    "     * The main table, must only have the total number, for all fields. This is the 'Type'.\n",
    "     * Dates of transition may be studied later for indiicating when new points were discovered/observed\n",
    "* \"Total_flowers\" which was used for stock checks is relevant only for the last day \"25 May\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the spaces in the column names\n",
    "df.columns=df.columns.str.replace(' ','_') #Rename columns to remove blank space\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique locations\n",
    "df1=df.copy(deep=True) #make copy to preserve original dataframe \n",
    "df1['Location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique locations\n",
    "len(df1['Location'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Location\" column cleaning algorithm\n",
    "Since location code depended on relative tree position, some codes were updated on later date to represent location more clearly. These tranistioned locations have to be regularised to the most recent code.\n",
    "* Iterate from bottom to top since changes apply to all preceding instances.\n",
    "* When a \"a->b\" occurs, for all preceding index locations containing a, replace with b.\n",
    "* At the transitioning \"->\" locations retain only the updated value.\n",
    "\n",
    "Observations:\n",
    "- Some transitions had a space: 10*s->' '10*m. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On what dates did the location update happen\n",
    "df1[df1['Location'].str.contains('->')]\n",
    "#Notice how some transitions have a space 10*s-> 10*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Location']=df1['Location'].str.replace(' ','') #remove blank space in location column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indi, rowi in df1[::-1].iterrows(): #iterate the rows from bottom to top\n",
    "    if '->' in rowi['Location']:\n",
    "        a=df1.loc[indi,'Location'].split('->')[0]\n",
    "        b=df1.loc[indi,'Location'].split('->')[1]\n",
    "        df1.at[indi,'Location']=b #update transitions to second value\n",
    "        for indj, rowj in df1[indi:None:-1].iterrows():  #from transitioned value, change all previous references\n",
    "            if rowj['Location']==a:\n",
    "                df1.at[indj,'Location']=b    #use \".at\" since iterrows uses a copy which will not update original value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Location'].unique() #check if all locations are unique and not transitioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check 'Total_points' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplcite values of transition, keeping preserving only the first date of the transition\n",
    "df1[df1['Total_points'].str.contains('->', na=False)].drop_duplicates(subset=['Location','Total_points'], keep='first')\n",
    "#After inserting dictionary of \"rain/irrigated\" check correlation of new flowering points through \"Total_points\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check 'Points_flowering' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique dates on which new flowering points transitioned up or down\n",
    "df1[df1['Points_flowering'].str.contains('->', na=False)].drop_duplicates(subset=['Location','Points_flowering'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned table to csv\n",
    "df1.to_csv('Clean_table.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the day with max new flowers:\n",
    "df1=pd.read_csv('Clean_table.csv')\n",
    "desc_maxflowers=pd.DataFrame(df1.groupby('Date')['New_flowers'].sum()).sort_values('New_flowers',ascending=False)\n",
    "maxflow_date=desc_maxflowers.index[0]\n",
    "max_date=df1[df1['Date']== maxflow_date]\n",
    "#len(max_date)\n",
    "#max_date\n",
    "# type(df1['New_flowers'][2])\n",
    "\n",
    "#Number of locations which have atleast 1 flower\n",
    "seas_locs=len(max_date[max_date['New_flowers'] != 0]) # 40 locs; Total locs is 62; 62 is still a much smaller part of total grid.\n",
    "max_date.sort_values('New_flowers',ascending=False,inplace=True) # Sort the locs in desc order of flowers\n",
    "\n",
    "#Number of locs which cumulate to 80%\n",
    "max_date['flow_cumul']=max_date['New_flowers'].cumsum()\n",
    "eigtper=max_date['flow_cumul'].iloc[-1]*0.8 #Value of 80% of the flowers\n",
    "len(max_date[max_date['flow_cumul']<eigtper]) # 19 locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new cols for each date: Flowering locs(>0);Eighty_perc_locs\n",
    "## O/p df Date; Total flowers; Flow_locs; eighty_locs\n",
    "\n",
    "\n",
    "#Function for counting locations which are flowering \"Flow_locs\"\n",
    "def flocs(x):\n",
    "    l=len(x[x!=0.0])#transform takes 'x' as the column x['a'] (series)\n",
    "    return(l)\n",
    "\n",
    "#Function for counting minimum no. of locs which have 80% of flowers\n",
    "def eigtlocs(x):\n",
    "    y=x.sort_values(ascending=False) #sort in descending to get min locations having max flowers\n",
    "    c=y.cumsum()\n",
    "    eightper=c.iloc[-1]*0.8\n",
    "    l=len(c[c<eightper])\n",
    "    return(l)\n",
    "    \n",
    "df2=df1.copy()\n",
    "df2['Total_New']=df2.groupby('Date')['New_flowers'].transform(sum) #New col with sum of flowers each day\n",
    "#df2[df2['Date']== '23 Apr 20']\n",
    "df2['Flow_locs']=df2.groupby('Date')['New_flowers'].transform(flocs)\n",
    "df2['Eighty_perc_locs']=df2.groupby('Date')['New_flowers'].transform(eigtlocs)\n",
    "#df2[df2['Date']== '22 Apr 20'] # For testing against max_flower_date from previous code block\n",
    "\n",
    "#Clean table grouped by our relevant columns\n",
    "perc_opt=df2.groupby('Date',sort=False)[['Total_New','Flow_locs','Eighty_perc_locs']].mean()\n",
    "\n",
    "#Column for focus percentage of locations having 80% of total flowers\n",
    "perc_opt['day_foc_perc']=perc_opt['Eighty_perc_locs']/perc_opt['Flow_locs']*100\n",
    "\n",
    "perc_opt.head()\n",
    "#perc_opt[perc_opt.index=='22 Apr 20']\n",
    "round(perc_opt['day_foc_perc'].mean(),1) # Mean focus percentage. #49.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are more optimisation figures which may be relevant:\n",
    "## 80% holding locs compared with flowering locs of the day : day_foc_perc\n",
    "## 80% holding locs compared with total flowering locs : seas_foc_perc\n",
    "## 80% holding locs compared with full walking path(checking for new locs) : grid_foc_perc\n",
    "perc_opt['day_foc_perc']=perc_opt['Eighty_perc_locs']/perc_opt['Flow_locs']*100\n",
    "perc_opt['seas_foc_perc']=perc_opt['Eighty_perc_locs']/seas_locs*100\n",
    "perc_opt['grid_foc_perc']=perc_opt['Eighty_perc_locs']/80*100\n",
    "perc_opt[perc_opt.index=='22 Apr 20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise date vs foc_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total new flowers per day across season\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.xticks(rotation=90)\n",
    "#sns.catplot(x='Date', y='New_flowers',data=df1,estimator=sum, kind='bar', ci= False, palette='Blues_r')\n",
    "sns.barplot(x='Date', y='New_flowers',data=df1,estimator=sum, ci= False, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up 'Total_points' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Total_points' column to reflect only updated count\n",
    "df2=df1.copy(deep=True) #save all previous transformations \n",
    "df2['Total_points']=df2['Total_points'].astype(str)\n",
    "for ind,row in df2.iterrows():\n",
    "    if '->' in row['Total_points']:\n",
    "        df2.at[ind,'Total_points']=df2.loc[ind,'Total_points'].split('->')[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behaviors based on type (number of flowering points)\n",
    "Overwrite all values in 'total_points' to only the last updated value. Most cases this is the max value for the location. \"Type\" of a vine is defined by the number of flowering points it contains 'Total_points'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite all values in total_points to only the highest value.\n",
    "df2.groupby(['Location','Total_points']).sum() #check where there are multiple values for total_points\n",
    "df2[df2['Location']=='10*2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Total_points']=df2['Total_points'].astype(float) #convert column to float for max operation.\n",
    "df2['New_flowers']=df2['New_flowers'].astype(float) \n",
    "#convert \"Total_points\" to highest value within subgroup\n",
    "df2['Total_points']=df2.groupby('Location')['Total_points'].transform(lambda x: x.max()) \n",
    "\n",
    "#Remove certain locations which became redundant due to updated location ID \n",
    "df3 = df2[df2.Location != {'8*3a2s','8*3a','7*c','10*2m'}]\n",
    "#df3.groupby(['Location','Total_points']).sum()  #to check if operation was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Season total of new flowers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='Total_points', y='New_flowers',data=df3,estimator=sum, ci= False, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New flowers per day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df3.replace(0,np.nan)\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=df3,x='Total_points',y='New_flowers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "g=sns.swarmplot(data=df3,x='Total_points',y='New_flowers', hue='Location')\n",
    "g.get_legend().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dot of a certain color represents the number of new flowers on a particular day by a paricular location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count of vines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of vines flowering for the year\n",
    "n=len(df3['Location'].unique())\n",
    "print(\"There are a total of\", n ,\"unique flowering locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of vines of a particular type\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "df3.groupby(['Total_points'])['Location'].nunique().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the plot above, the majority of the vines are the 1,2, and 3 point vines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days of flowering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of days of flowering by type\n",
    "a=df3.groupby(['Total_points','Location'])['New_flowers'].count()\n",
    "a=pd.DataFrame(a)\n",
    "a.reset_index(inplace=True)\n",
    "a.rename(columns={'New_flowers': 'Days'}, inplace=True)\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.swarmplot(data=a,x='Total_points',y='Days', hue='Location').get_legend().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "- Intuitively, it feels like there may be a correlation between \"points_flowering\" (currently flowering) and number of new flowers for the day. \n",
    "- Explore possible patternality of new flower occurence:\n",
    "    - a) as a group. Inference is likely common to all vines.\n",
    "    - b) as an individual vine. Possible a factor of 'points_flowering' or specific other conditions.\n",
    " * We only have data of 'type' based on number of flowering points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare total flowers with type (Total_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df3.groupby(['Location']).agg({\n",
    "                         'Total_points': 'mean', \n",
    "                         'New_flowers':'sum', \n",
    "                          })\n",
    "sns.jointplot(data=a,x='Total_points', y='New_flowers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up 'Points_flowering' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Points_flowering' column to reflect only updated count\n",
    "df4=df3.copy(deep=True) #save all previous transformations \n",
    "df4['Points_flowering']=df4['Points_flowering'].str.replace(' ','') #remove blank space in location column\n",
    "df4['Points_flowering']=df4['Points_flowering'].str.replace('–','-') #format of dash made uniform\n",
    "df4['Points_flowering']=df4['Points_flowering'].astype(str)\n",
    "for ind,row in df4.iterrows():\n",
    "    if '->' in row['Points_flowering']:\n",
    "        df4.at[ind,'Points_flowering']=df4.loc[ind,'Points_flowering'].split('->')[1]\n",
    "\n",
    "# Check if succesful        \n",
    "df4[df4['Points_flowering'].str.contains('->', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[df4['Points_flowering'].str.contains('–>', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare new flowers with points flowering on a given day\n",
    "Note that a particualr vine may conain 2,3,4.. etc points actively fowering at different points in the season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['Points_flowering']=df4['Points_flowering'].astype(float)\n",
    "sns.jointplot(data=df4,x='Points_flowering', y='New_flowers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pareto of flowering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loc_max=pd.DataFrame(df4.groupby('Location')['New_flowers'].sum())\n",
    "Loc_max.sort_values(by='New_flowers',ascending=False, inplace=True )\n",
    "Loc_max['Cum_sum']=Loc_max['New_flowers'].cumsum()\n",
    "Loc_max['Cum_percentage']=Loc_max['Cum_sum']*100/Loc_max['New_flowers'].sum()\n",
    "Loc_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loc_max.reset_index(inplace=True)\n",
    "trace1 = dict(type='bar',\n",
    "    x=Loc_max['Location'],\n",
    "    y=Loc_max['New_flowers'],\n",
    "    marker=dict(\n",
    "        color='#2196F3'\n",
    "    ),\n",
    "    name='New_flowers',\n",
    "    opacity=0.8\n",
    ")\n",
    "\n",
    "trace2 = dict(type='scatter',\n",
    "    x=Loc_max['Location'],\n",
    "    y=Loc_max['Cum_percentage'],\n",
    "    marker=dict(\n",
    "        color='#263238'\n",
    "    ),\n",
    "    line=dict(\n",
    "        color= '#263238', \n",
    "        width= 1.5),\n",
    "    name='Cumulative Percentage',\n",
    "    xaxis='x1', \n",
    "    yaxis='y2' \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs,init_notebook_mode,plot,iplot\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [trace1, trace2]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='[Pareto Analysis of Total New Flowers by Locations',\n",
    "    legend= dict(orientation=\"h\"),\n",
    "    \n",
    "    yaxis=dict(\n",
    "        range=[0,202],\n",
    "        title='Total New Flowers',\n",
    "        titlefont=dict(\n",
    "            color=\"#2196F3\"\n",
    "        )\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='Cumulative Percentage of New Flowers ',\n",
    "        titlefont=dict(\n",
    "            color='#263238'\n",
    "        ),\n",
    "        range=[0,105],\n",
    "        overlaying='y',\n",
    "        anchor='x',\n",
    "        side='right'\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename=\"pareto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of new flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total = df4['New_flowers'].sum()\n",
    "print (Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation\n",
    "#df4[ \"New_flowers\"].fillna(0)\n",
    "std_df = df4.groupby(\"Date\")[ \"New_flowers\"].sum()\n",
    "std_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_df="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of dates\n",
    "n = len(pd.unique(df4['Date'])) \n",
    "  \n",
    "print(\"No.of.unique values :\",  \n",
    "      n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What questions can be answered with improving year on year data:\n",
    "**Data collection from drone-phase1 :**\n",
    "* Inputs from a drone flight on a given day: \n",
    "    1. Number of locations- New ones may be discovered on some days\n",
    "    2. Number of points_flowering(active)- if it has detected a flower once set 'active' flag\n",
    "    3. Total number of new flowers.\n",
    "\n",
    "**Immediate intelligence**\n",
    "1. Best walking route to pollinate the flowers.\n",
    "    \n",
    "**Based on data gathered from previous years (from the data lake) we could possibly infer:**\n",
    "* Where on the normal distribution curve we are, and hence:\n",
    "    * Number of flowers which have been lost (previous dates)\n",
    "    * Number of flowers which are yet to arrive in future.\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
